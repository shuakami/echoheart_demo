{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "61c0_Ls4XUJ0"
   },
   "source": [
    "# 在 Google Colab 中进行 EchoHeart 的 Qwen 微调\n",
    "\n",
    "这个 Notebook 会自动配置环境、启动微调 (QLoRA)、运行测试、合并 LoRA 适配器并导出 GGUF 模型。\n",
    "\n",
    "**步骤：**\n",
    "1. 克隆/更新 GitHub 仓库并定义路径。\n",
    "2. 安装必要的依赖项。\n",
    "3. 运行训练脚本 (QLoRA)。\n",
    "4. (可选) 运行测试脚本与微调后的模型(适配器)交互。\n",
    "5. 合并 LoRA 适配器到基础模型。\n",
    "6. (可选) 将合并后的模型转换为 GGUF 格式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d8soImHTXUJ4"
   },
   "outputs": [],
   "source": [
    "# 1. 克隆/更新仓库并定义路径\n",
    "import os\n",
    "repo_path = '/content/echoheart_demo'\n",
    "\n",
    "# --- 配置变量 (硬编码) ---\n",
    "base_model_name = \"Qwen/Qwen2.5-1.5B-Instruct\" \n",
    "adapter_path = \"/content/echoheart_demo/output/qwen2-1.5b-qlora-ft\" \n",
    "merged_model_path = \"/content/echoheart_demo/output/qwen2-1.5b-merged-ft\" \n",
    "gguf_output_file = f\"{merged_model_path}/gguf-model-f16.gguf\" \n",
    "# ---------------\n",
    "\n",
    "if not os.path.exists(repo_path):\n",
    "  print(f\"Cloning repository into {repo_path}...\")\n",
    "  !git clone https://github.com/shuakami/echoheart_demo.git {repo_path}\n",
    "else:\n",
    "  print(f\"Repository already exists at {repo_path}.\")\n",
    "\n",
    "%cd {repo_path}\n",
    "\n",
    "print(\"Pulling latest changes...\")\n",
    "!git pull origin master\n",
    "\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ZzzYcswXUJ5"
   },
   "outputs": [],
   "source": [
    "# 2. 安装依赖\n",
    "print(\"Installing dependencies from requirements.txt...\")\n",
    "!pip install -q -r requirements.txt\n",
    "\n",
    "print(\"Applying dependency fixes...\")\n",
    "!pip install fsspec==2024.12.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OCd-DEGuXUJ6"
   },
   "outputs": [],
   "source": [
    "# 3. 运行训练脚本\n",
    "print(\"Starting training...\")\n",
    "!python train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-GFKaIkLXUJ6"
   },
   "source": [
    "## 训练完成！\n",
    "\n",
    "微调后的模型保存在 Colab 环境文件系统的 `output/qwen-ft` 目录中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "added_test_step"
   },
   "outputs": [],
   "source": [
    "# 4. 运行测试脚本\n",
    "print(\"Starting non-interactive testing session...\")\n",
    "!python test_model.py --base_model_name Qwen/Qwen2.5-1.5B-Instruct --adapter_path output/qwen2-1.5b-qlora-ft "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gguf_markdown"
   },
   "source": [
    "## 5. (可选) 转换为 GGUF 格式\n",
    "\n",
    "**注意:** 直接转换包含 LoRA 适配器的模型目录到 GGUF 通常**不可行**或效果不佳。`llama.cpp` 的转换脚本期望一个完整的模型目录。\n",
    "理想情况下，应先执行**模型合并**步骤，将 LoRA 适配器合并回基础模型，保存为一个新的完整模型目录，然后再对合并后的目录进行 GGUF 转换。\n",
    "以下代码**尝试直接转换适配器目录**（通常会失败），如果需要执行合并，请告知。\n",
    "转换后的文件将尝试保存在 `{gguf_output_file}`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "added_gguf_step"
   },
   "outputs": [],
   "source": [
    "# 运行 LoRA 合并脚本\n",
    "print(\"Starting LoRA merge...\")\n",
    "!python merge_lora.py --base_model_name \"Qwen/Qwen2.5-1.5B-Instruct\" --adapter_path \"/content/echoheart_demo/output/qwen2-1.5b-qlora-ft\" --output_path \"/content/echoheart_demo/output/qwen2-1.5b-merged-ft\"\n",
    "\n",
    "# 转换为 GGUF\n",
    "print(\"Starting GGUF conversion...\")\n",
    "!python convert_to_gguf.py --model_dir /content/echoheart_demo/output/qwen2-1.5b-merged-ft --output_file /content/echoheart_demo/output/qwen2-1.5b-merged-ft/gguf-model-f16.gguf --out_type f16"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
