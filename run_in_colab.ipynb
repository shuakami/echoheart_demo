{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "notebook_intro_markdown"
   },
   "source": [
    "# 在 Google Colab 中进行 EchoHeart 的 Qwen 微调 (可配置版 v2)\n",
    "\n",
    "这个 Notebook 会自动配置环境、启动微调 (QLoRA)、运行测试、合并 LoRA 适配器并导出 GGUF 模型。\n",
    "\n",
    "**配置**：您可以通过修改下面的第一个代码单元格中的变量来指定要使用的基础模型和数据集。\n",
    "\n",
    "**步骤：**\n",
    "1. 配置变量、克隆/更新 GitHub 仓库并定义路径。\n",
    "2. 安装必要的依赖项。\n",
    "3. 运行训练脚本 (QLoRA)。\n",
    "4. (可选) 运行测试脚本与微调后的模型(适配器)交互。\n",
    "5. 合并 LoRA 适配器到基础模型。\n",
    "6. (可选) 将合并后的模型转换为 GGUF 格式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "config_and_setup_cell"
   },
   "outputs": [],
   "source": [
    "# 1. 配置变量、克隆/更新仓库并定义路径\n",
    "import os\n",
    "\n",
    "# --- 配置变量 (在此处修改！) ---\n",
    "# 指定要微调的基础模型 (Hugging Face 名称或路径)\n",
    "base_model_name = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
    "# 指定数据集文件路径 (相对于仓库根目录)\n",
    "dataset_file = \"data/converted_dataset.json\" # 确保这个文件存在于您的仓库中\n",
    "# ------------------------------\n",
    "\n",
    "# --- 自动生成路径 (基于上面的配置) ---\n",
    "model_name_slug = base_model_name.split('/')[-1] # 从模型名称生成安全的文件名部分\n",
    "adapter_output_dir = f\"output/{model_name_slug}-qlora-ft\"\n",
    "merged_model_output_dir = f\"output/{model_name_slug}-merged-ft\"\n",
    "gguf_output_filename = f\"gguf-{model_name_slug}-f16.gguf\" # GGUF文件名\n",
    "gguf_output_dir = merged_model_output_dir # GGUF文件保存在合并模型的目录中\n",
    "# -------------------------------------\n",
    "\n",
    "# -- 固定路径和计算绝对路径 --\n",
    "repo_path = '/content/echoheart_demo'\n",
    "adapter_path = os.path.join(repo_path, adapter_output_dir)\n",
    "merged_model_path = os.path.join(repo_path, merged_model_output_dir)\n",
    "dataset_abs_path = os.path.join(repo_path, dataset_file)\n",
    "gguf_output_abs_path = os.path.join(repo_path, gguf_output_dir, gguf_output_filename) \n",
    "# --------------\n",
    "\n",
    "print(\"--- 配置信息 ---\")\n",
    "print(f\"基础模型: {base_model_name}\")\n",
    "print(f\"数据集文件 (相对路径): {dataset_file}\")\n",
    "print(f\"数据集文件 (绝对路径): {dataset_abs_path}\")\n",
    "print(f\"适配器输出目录: {adapter_path}\")\n",
    "print(f\"合并模型输出目录: {merged_model_path}\")\n",
    "print(f\"GGUF 输出文件: {gguf_output_abs_path}\")\n",
    "print(\"------------------\")\n",
    "\n",
    "# 克隆或更新仓库\n",
    "if not os.path.exists(repo_path):\n",
    "  print(f\"\\nCloning repository into {repo_path}...\")\n",
    "  !git clone https://github.com/shuakami/echoheart_demo.git {repo_path}\n",
    "else:\n",
    "  print(f\"\\nRepository already exists at {repo_path}.\")\n",
    "\n",
    "%cd {repo_path}\n",
    "\n",
    "print(\"Pulling latest changes...\")\n",
    "!git pull origin master\n",
    "\n",
    "# 确保数据集文件存在\n",
    "if not os.path.exists(dataset_abs_path):\n",
    "  print(f\"\\n[bold red]错误：指定的数据集文件不存在: {dataset_abs_path}[/bold red]\")\n",
    "  # 可以在这里引发错误停止执行: raise FileNotFoundError(f\"Dataset file not found: {dataset_abs_path}\")\n",
    "else:\n",
    "  print(f\"\\n数据集文件确认存在: {dataset_abs_path}\")\n",
    "\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_deps_cell"
   },
   "outputs": [],
   "source": [
    "# 2. 安装依赖\n",
    "print(\"Installing dependencies from requirements.txt...\")\n",
    "!pip install -q -r requirements.txt\n",
    "\n",
    "print(\"Applying dependency fixes...\")\n",
    "!pip install -q fsspec==2024.12.0 # 使用 -q 安静模式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run_training_cell_fixed"
   },
   "outputs": [],
   "source": [
    "# 3. 运行训练脚本 (QLoRA)\n",
    "print(\"Starting QLoRA training...\")\n",
    "# 通过命令行参数传递模型名称和数据集路径 (使用变量)\n",
    "!python train.py --base_model_name \"{base_model_name}\" --dataset_file \"{dataset_file}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "training_complete_markdown_updated"
   },
   "source": [
    "## 训练完成！\n",
    "\n",
    "QLoRA 适配器应保存在 Colab 文件系统的 `{adapter_path}` 目录中。\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test_adapter_cell_fixed"
   },
   "outputs": [],
   "source": [
    "# 4. (可选) 运行测试脚本 (测试适配器效果)\n",
    "print(\"Starting non-interactive testing session with adapter...\")\n",
    "# 使用变量调用测试脚本\n",
    "!python test_model.py --base_model_name \"{base_model_name}\" --adapter_path \"{adapter_path}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "merge_lora_markdown_fixed"
   },
   "source": [
    "## 5. 合并 LoRA 适配器\n",
    "\n",
    "以下步骤将加载基础模型和训练好的 LoRA 适配器，并将它们合并成一个完整的模型。\n",
    "合并后的模型将保存在 `{merged_model_path}`。"
   ]
  },
  {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {
        "id": "merge_lora_cell_fixed"
    },
    "outputs": [],
    "source": [
    "# 5. 运行 LoRA 合并脚本\n",
    "print(\"Starting LoRA merge...\")\n",
    "# 使用变量调用合并脚本\n",
    "!python merge_lora.py --base_model_name \"{base_model_name}\" --adapter_path \"{adapter_path}\" --output_path \"{merged_model_path}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gguf_markdown_fixed"
   },
   "source": [
    "## 6. (可选) 转换为 GGUF 格式\n",
    "\n",
    "现在我们将使用**合并后**的模型目录进行 GGUF 转换。\n",
    "转换后的 GGUF 文件将保存在 `{gguf_output_abs_path}`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "convert_gguf_cell_fixed"
   },
   "outputs": [],
   "source": [
    "# 运行 LoRA 合并脚本\n",
    "print(\"Starting LoRA merge...\")\n",
    "!python merge_lora.py --base_model_name \"Qwen/Qwen2.5-1.5B-Instruct\" --adapter_path \"/content/echoheart_demo/output/qwen2-1.5b-qlora-ft\" --output_path \"/content/echoheart_demo/output/qwen2-1.5b-merged-ft\"\n",
    "\n",
    "# 转换为 GGUF\n",
    "print(\"Starting GGUF conversion...\")\n",
    "!python convert_to_gguf.py --model_dir /content/echoheart_demo/output/qwen2-1.5b-merged-ft --output_file /content/echoheart_demo/output/qwen2-1.5b-merged-ft/gguf-model-f16.gguf --out_type f16"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
