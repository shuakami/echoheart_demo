{
  "cells": [
   {
    "cell_type": "markdown",
    "metadata": {
     "id": "61c0_Ls4XUJ0"
    },
    "source": [
     "# 在 Google Colab 中进行 EchoHeart 的 Qwen 微调\n",
     "\n",
     "这个 Notebook 会自动配置环境、启动微调、运行测试并导出 GGUF 模型。\n",
     "\n",
     "**步骤：**\n",
     "1. 克隆/更新 GitHub 仓库。\n",
     "2. 安装必要的依赖项。\n",
     "3. 运行训练脚本 (QLoRA)。\n",
     "4. (可选) 运行测试脚本与微调后的模型(适配器)交互。\n",
     "5. (可选) 将微调后的模型(合并后)转换为 GGUF 格式。"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {
     "id": "d8soImHTXUJ4"
    },
    "outputs": [],
    "source": [
     "# 1. 克隆/更新仓库\n",
     "import os\n",
     "repo_path = '/content/echoheart_demo'\n",
     "base_model_name = \"Qwen/Qwen2.5-1.5B-Instruct\" # 定义基础模型名称变量
 ",
     "adapter_path = \"output/qwen2-1.5b-qlora-ft\" # 定义适配器路径变量
 ",
     "gguf_output_file = f\"{adapter_path}/gguf-model-f16.gguf\" # 定义GGUF输出文件名
 ",
     "\n",
     "if not os.path.exists(repo_path):\n",
     "  print(f\"Cloning repository into {repo_path}...\")\n",
     "  !git clone https://github.com/shuakami/echoheart_demo.git {repo_path}\n",
     "else:\n",
     "  print(f\"Repository already exists at {repo_path}.\")\n",
     "\n",
     "%cd {repo_path}\n",
     "\n",
     "print(\"Pulling latest changes...\")\n",
     "!git pull origin master\n",
     "\n",
     "!pwd"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {
     "id": "0ZzzYcswXUJ5"
    },
    "outputs": [],
    "source": [
     "# 2. 安装依赖\n",
     "print(\"Installing dependencies from requirements.txt...\")\n",
     "!pip install -q -r requirements.txt\n",
     "\n",
     "print(\"Applying dependency fixes...\")\n",
     "!pip install fsspec==2024.12.0"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {
     "id": "OCd-DEGuXUJ6"
    },
    "outputs": [],
    "source": [
     "# 3. 运行训练脚本 (QLoRA)\n",
     "print(\"Starting QLoRA training...\")\n",
     "!python train.py"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {
     "id": "-GFKaIkLXUJ6"
    },
    "source": [
     "## 训练完成！\n",
     "\n",
     f"QLoRA 适配器保存在 Colab 环境文件系统的 `{adapter_path}` 目录中。"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {
     "id": "added_test_step"
    },
    "outputs": [],
    "source": [
     "# 4. (可选) 运行测试脚本\n",
     "print(\"Starting non-interactive testing session...\")\n",
     "# 使用绝对路径和正确的参数调用测试脚本\n",
     f"!python test_model.py --base_model_name {base_model_name} --adapter_path {adapter_path}"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {
     "id": "gguf_markdown"
    },
    "source": [
     "## 5. (可选) 转换为 GGUF 格式\n",
     "\n",
     "**注意:** 直接转换包含 LoRA 适配器的模型到 GGUF 可能不被 `llama.cpp` 的脚本直接支持或效果不佳。\n",
     "理想情况下，应先将 LoRA 适配器合并回基础模型，然后再进行 GGUF 转换。\n",
     "以下代码尝试直接转换，如果失败或需要合并，请告知。\n",
     f"转换后的文件将尝试保存在 `{gguf_output_file}`。"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {
     "id": "added_gguf_step"
    },
    "outputs": [],
    "source": [
     "# 5. 转换为 GGUF (尝试直接转换适配器模型目录)\n",
     "# !! 可能需要先合并 LoRA !!
 ",
     "print(\"Attempting GGUF conversion (may require merging LoRA first)...\")\n",
     f"!python convert_to_gguf.py --model_dir {adapter_path} --output_file {gguf_output_file} --out_type f16"
    ]
   }
  ],
  "metadata": {
   "colab": {
    "provenance": [],
    "toc_visible": true
   },
   "kernelspec": {
    "display_name": "Python 3",
    "language": "python",
    "name": "python3"
   },
   "language_info": {
    "codemirror_mode": {
     "name": "ipython",
     "version": 3
    },
    "file_extension": ".py",
    "mimetype": "text/x-python",
    "name": "python",
    "nbconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": "3.10.12"
   }
  },
  "nbformat": 4,
  "nbformat_minor": 4
 }
 